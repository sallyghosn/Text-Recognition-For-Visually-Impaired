{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CRNN_with_CTCLoss_.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "OGVwrP65_pZG"
      },
      "source": [
        "import os\n",
        "import fnmatch\n",
        "import cv2\n",
        "import numpy as np\n",
        "import string\n",
        "import time\n",
        "\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "from keras.layers import Dense, LSTM, Reshape, BatchNormalization, Input, Conv2D, MaxPool2D, Lambda, Bidirectional\n",
        "from keras.models import Model\n",
        "from keras.activations import relu, sigmoid, softmax\n",
        "import keras.backend as K\n",
        "from keras.utils import to_categorical\n",
        "from keras.callbacks import ModelCheckpoint"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uo_7gWMaCDwn"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NDV7ZJJj_sWk",
        "outputId": "41d16810-af2f-4f1c-e692-3748bf45255c"
      },
      "source": [
        "char_list = 'abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789'\n",
        "print (len(char_list))\n",
        "import tensorflow as tf\n",
        "\n",
        " \n",
        "def encode_to_labels(txt):\n",
        "    # encoding each output word into digits\n",
        "    dig_lst = []\n",
        "    for index, char in enumerate(txt):\n",
        "        try:\n",
        "            dig_lst.append(char_list.index(char))\n",
        "        except:\n",
        "            print(char)\n",
        "        \n",
        "    return dig_lst"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "62\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mvF4DINq_5v6"
      },
      "source": [
        "path = '/content/drive/MyDrive/minidat'\n",
        "\n",
        "\n",
        "# lists for training dataset\n",
        "training_img = []\n",
        "training_txt = []\n",
        "train_input_length = []\n",
        "train_label_length = []\n",
        "orig_txt = []\n",
        "\n",
        "#lists for validation dataset\n",
        "valid_img = []\n",
        "valid_txt = []\n",
        "valid_input_length = []\n",
        "valid_label_length = []\n",
        "valid_orig_txt = []\n",
        "\n",
        "max_label_len = 0\n",
        "\n",
        "i =1 \n",
        "flag = 0\n",
        "\n",
        "for root, dirnames, filenames in os.walk(path):\n",
        "\n",
        "    for f_name in fnmatch.filter(filenames, '*.jpg'):\n",
        "        # read input image and convert into gray scale image\n",
        "        img = cv2.cvtColor(cv2.imread(os.path.join(root, f_name)), cv2.COLOR_BGR2GRAY)   \n",
        "\n",
        "        # convert each image of shape (32, 128, 1)\n",
        "        w, h = img.shape\n",
        "        if h > 128 or w > 32:\n",
        "            continue\n",
        "        if w < 32:\n",
        "            add_zeros = np.ones((32-w, h))*255\n",
        "            img = np.concatenate((img, add_zeros))\n",
        "\n",
        "        if h < 128:\n",
        "            add_zeros = np.ones((32, 128-h))*255\n",
        "            img = np.concatenate((img, add_zeros), axis=1)\n",
        "        img = np.expand_dims(img , axis = 2)\n",
        "        \n",
        "        img = img/255.\n",
        "        \n",
        "        # get the text from the image\n",
        "        txt = f_name.split('_')[1]\n",
        "        \n",
        "        if len(txt) > max_label_len:\n",
        "            max_label_len = len(txt)\n",
        "            \n",
        "           \n",
        "        if i%10 == 0:     \n",
        "            valid_orig_txt.append(txt)   \n",
        "            valid_label_length.append(len(txt))\n",
        "            valid_input_length.append(31)\n",
        "            valid_img.append(img)\n",
        "            valid_txt.append(encode_to_labels(txt))\n",
        "        else:\n",
        "            orig_txt.append(txt)   \n",
        "            train_label_length.append(len(txt))\n",
        "            train_input_length.append(31)\n",
        "            training_img.append(img)\n",
        "            training_txt.append(encode_to_labels(txt)) \n",
        "        \n",
        "      \n",
        "        if i == :5000\n",
        "            flag = 1\n",
        "            break\n",
        "        i+=1\n",
        "    if flag == 1:\n",
        "        break\n",
        "        \n",
        "# pad each output label to maximum text length\n",
        "\n",
        "train_padded_txt = pad_sequences(training_txt, maxlen=max_label_len, padding='post', value = len(char_list))\n",
        "valid_padded_txt = pad_sequences(valid_txt, maxlen=max_label_len, padding='post', value = len(char_list))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3G5l7cH-EOOK",
        "outputId": "80dcc133-636c-4c44-88f0-27a2d40a61e5"
      },
      "source": [
        "inputs = Input(shape=(32,128,1))\n",
        " \n",
        "# convolution layer with kernel size (3,3)\n",
        "conv_1 = Conv2D(64, (3,3), activation = 'relu', padding='same')(inputs)\n",
        "# poolig layer with kernel size (2,2)\n",
        "pool_1 = MaxPool2D(pool_size=(2, 2), strides=2)(conv_1)\n",
        " \n",
        "conv_2 = Conv2D(128, (3,3), activation = 'relu', padding='same')(pool_1)\n",
        "pool_2 = MaxPool2D(pool_size=(2, 2), strides=2)(conv_2)\n",
        " \n",
        "conv_3 = Conv2D(256, (3,3), activation = 'relu', padding='same')(pool_2)\n",
        " \n",
        "conv_4 = Conv2D(256, (3,3), activation = 'relu', padding='same')(conv_3)\n",
        "# poolig layer with kernel size (2,1)\n",
        "pool_4 = MaxPool2D(pool_size=(2, 1))(conv_4)\n",
        " \n",
        "conv_5 = Conv2D(512, (3,3), activation = 'relu', padding='same')(pool_4)\n",
        "# Batch normalization layer\n",
        "batch_norm_5 = BatchNormalization()(conv_5)\n",
        " \n",
        "conv_6 = Conv2D(512, (3,3), activation = 'relu', padding='same')(batch_norm_5)\n",
        "batch_norm_6 = BatchNormalization()(conv_6)\n",
        "pool_6 = MaxPool2D(pool_size=(2, 1))(batch_norm_6)\n",
        " \n",
        "conv_7 = Conv2D(512, (2,2), activation = 'relu')(pool_6)\n",
        " \n",
        "squeezed = Lambda(lambda x: K.squeeze(x, 1))(conv_7)\n",
        " \n",
        "# bidirectional LSTM layers with units=128\n",
        "blstm_1 = Bidirectional(LSTM(128, return_sequences=True, dropout = 0.2))(squeezed)\n",
        "blstm_2 = Bidirectional(LSTM(128, return_sequences=True, dropout = 0.2))(blstm_1)\n",
        " \n",
        "outputs = Dense(len(char_list)+1, activation = 'softmax')(blstm_2)\n",
        "# model to be used at test time\n",
        "act_model = Model(inputs, outputs)\n",
        "act_model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 32, 128, 1)]      0         \n",
            "_________________________________________________________________\n",
            "conv2d (Conv2D)              (None, 32, 128, 64)       640       \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 16, 64, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 16, 64, 128)       73856     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 8, 32, 128)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 8, 32, 256)        295168    \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 8, 32, 256)        590080    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 4, 32, 256)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 4, 32, 512)        1180160   \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 4, 32, 512)        2048      \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 4, 32, 512)        2359808   \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 4, 32, 512)        2048      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 2, 32, 512)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_6 (Conv2D)            (None, 1, 31, 512)        1049088   \n",
            "_________________________________________________________________\n",
            "lambda (Lambda)              (None, 31, 512)           0         \n",
            "_________________________________________________________________\n",
            "bidirectional (Bidirectional (None, 31, 256)           656384    \n",
            "_________________________________________________________________\n",
            "bidirectional_1 (Bidirection (None, 31, 256)           394240    \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 31, 63)            16191     \n",
            "=================================================================\n",
            "Total params: 6,619,711\n",
            "Trainable params: 6,617,663\n",
            "Non-trainable params: 2,048\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I8oTL0nRFa31"
      },
      "source": [
        "labels = Input(name='the_labels', shape=[max_label_len], dtype='float32')\n",
        "input_length = Input(name='input_length', shape=[1], dtype='int64')\n",
        "label_length = Input(name='label_length', shape=[1], dtype='int64')\n",
        " \n",
        " \n",
        "def ctc_lambda_func(args):\n",
        "    y_pred, labels, input_length, label_length = args\n",
        " \n",
        "    return K.ctc_batch_cost(labels, y_pred, input_length, label_length)\n",
        " \n",
        " \n",
        "loss_out = Lambda(ctc_lambda_func, output_shape=(1,), name='ctc')([outputs, labels, input_length, label_length])\n",
        "\n",
        "#model to be used at training time\n",
        "model = Model(inputs=[inputs, labels, input_length, label_length], outputs=loss_out)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TDiaWvK4Fen3"
      },
      "source": [
        "model.compile(loss={'ctc': lambda y_true, y_pred: y_pred}, optimizer = 'adam')\n",
        " \n",
        "filepath=\"best_model.hdf5\"\n",
        "checkpoint = ModelCheckpoint(filepath=filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='auto')\n",
        "callbacks_list = [checkpoint]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G9U5VO-hFkyt"
      },
      "source": [
        "training_img = np.array(training_img)\n",
        "train_input_length = np.array(train_input_length)\n",
        "train_label_length = np.array(train_label_length)\n",
        "\n",
        "valid_img = np.array(valid_img)\n",
        "valid_input_length = np.array(valid_input_length)\n",
        "valid_label_length = np.array(valid_label_length)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qkfzasGgFoBn",
        "outputId": "c5873957-62de-48a1-8df0-09024b128ec5"
      },
      "source": [
        "batch_size = 256\n",
        "epochs = 10\n",
        "h=model.fit(x=[training_img, train_padded_txt, train_input_length, train_label_length], y=np.zeros(len(training_img)), batch_size=batch_size, epochs = epochs, validation_data = ([valid_img, valid_padded_txt, valid_input_length, valid_label_length], [np.zeros(len(valid_img))]), verbose = 1, callbacks = callbacks_list)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "8/8 [==============================] - 254s 31s/step - loss: 60.8170 - val_loss: 29.3511\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 29.35110, saving model to best_model.hdf5\n",
            "Epoch 2/10\n",
            "8/8 [==============================] - 243s 30s/step - loss: 29.9793 - val_loss: 28.6485\n",
            "\n",
            "Epoch 00002: val_loss improved from 29.35110 to 28.64851, saving model to best_model.hdf5\n",
            "Epoch 3/10\n",
            "8/8 [==============================] - 245s 31s/step - loss: 28.9900 - val_loss: 28.2729\n",
            "\n",
            "Epoch 00003: val_loss improved from 28.64851 to 28.27286, saving model to best_model.hdf5\n",
            "Epoch 4/10\n",
            "8/8 [==============================] - 249s 31s/step - loss: 28.6221 - val_loss: 28.1393\n",
            "\n",
            "Epoch 00004: val_loss improved from 28.27286 to 28.13926, saving model to best_model.hdf5\n",
            "Epoch 5/10\n",
            "8/8 [==============================] - 243s 30s/step - loss: 28.4245 - val_loss: 28.1726\n",
            "\n",
            "Epoch 00005: val_loss did not improve from 28.13926\n",
            "Epoch 6/10\n",
            "8/8 [==============================] - 244s 30s/step - loss: 28.1259 - val_loss: 28.1568\n",
            "\n",
            "Epoch 00006: val_loss did not improve from 28.13926\n",
            "Epoch 7/10\n",
            "8/8 [==============================] - 242s 30s/step - loss: 28.1004 - val_loss: 28.0138\n",
            "\n",
            "Epoch 00007: val_loss improved from 28.13926 to 28.01383, saving model to best_model.hdf5\n",
            "Epoch 8/10\n",
            "8/8 [==============================] - 244s 30s/step - loss: 27.8718 - val_loss: 28.0686\n",
            "\n",
            "Epoch 00008: val_loss did not improve from 28.01383\n",
            "Epoch 9/10\n",
            "8/8 [==============================] - 251s 32s/step - loss: 27.6564 - val_loss: 28.1971\n",
            "\n",
            "Epoch 00009: val_loss did not improve from 28.01383\n",
            "Epoch 10/10\n",
            "8/8 [==============================] - 242s 30s/step - loss: 27.5709 - val_loss: 28.0657\n",
            "\n",
            "Epoch 00010: val_loss did not improve from 28.01383\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fc3d6bc7210>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    }
  ]
}